{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ....\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive data linkage without blocking\n",
    "\n",
    "# Installing the textdistance library\n",
    "# !conda install -c conda-forge textdistance (in terminal)\n",
    "\n",
    "import textdistance\n",
    "\n",
    "# Loading CSV into a pandas data frame\n",
    "df_1 = pd.read_csv('google_small.csv', encoding='ISO-8859-1')\n",
    "df_2 = pd.read_csv('amazon_small.csv', encoding='ISO-8859-1')\n",
    "\n",
    "### 1. Detecting duplication\n",
    "\n",
    "df_duplicated_google = df_1[df_1.duplicated()]\n",
    "df_duplicated_amazon = df_2[df_2.duplicated()]\n",
    "\n",
    "df_small_google = df_1\n",
    "df_small_amazon = df_2\n",
    "\n",
    "### No duplications were found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature engineering \n",
    "\n",
    "### Generate new feature with combination of 3 featueres.\n",
    "\n",
    "# Check for the type.\n",
    "type(df_small_amazon.description[0])\n",
    "\n",
    "# Replace missing values (NaN) with empty strings in the Amazon data frame.\n",
    "df_small_amazon_fix = df_small_amazon.replace(np.nan, '', regex=True)\n",
    "\n",
    "# Check for and count missing values in the Amazon data frame.\n",
    "df_small_amazon_fix.isnull().sum()\n",
    "\n",
    "# Create a new feature in the Amazon data frame by combining the 'title,' 'description,' and 'manufacturer' columns.\n",
    "df_small_amazon_fix['combined_feature'] = df_small_amazon_fix.title + df_small_amazon_fix.description + df_small_amazon_fix.manufacturer\n",
    "\n",
    "# Replace missing values (NaN) with empty strings in the Google data frame.\n",
    "df_small_google_fix = df_small_google.replace(np.nan, '', regex=True)\n",
    "\n",
    "# Check for and count missing values in the Google data frame.\n",
    "df_small_google_fix.isnull().sum()\n",
    "\n",
    "# Create a new feature in the Google data frame by combining the 'name,' 'description,' and 'manufacturer' columns.\n",
    "df_small_google_fix['combined_feature'] = df_small_google_fix.name + df_small_google_fix.description + df_small_google_fix.manufacturer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Using the similarity score on the newly engineered features and price\n",
    "\n",
    "## Cosine similarity function \n",
    "import re, math\n",
    "from collections import Counter\n",
    "\n",
    "WORD = re.compile(r'\\w+')\n",
    "\n",
    "def get_cosine(vec1, vec2):\n",
    "     intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "     numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "     sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "     sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "     denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "     if not denominator:\n",
    "        return 0.0\n",
    "     else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "def text_to_vector(text):\n",
    "     words = WORD.findall(text)\n",
    "     return Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store matched items by title or name.\n",
    "matched_list = pd.DataFrame()\n",
    "\n",
    "# Layer 1 - string match with title VS name\n",
    "for i in range(1, len(df_small_amazon.title)):\n",
    "    similar_score = []\n",
    "    matched_amazon_combined = []\n",
    "    matched_google_combined = []\n",
    "\n",
    "    # Create columns to hold the similar price for the further layer\n",
    "    matched_amazon_title = []\n",
    "    matched_google_title = []\n",
    "\n",
    "    matched_amazon_price = []\n",
    "    matched_google_price = []\n",
    "\n",
    "    matched_amazon_id = []\n",
    "    matched_google_id = []\n",
    "\n",
    "    for j in range(1, len(df_small_google.name)):\n",
    "        vector1 = text_to_vector(df_small_amazon_fix.title[i])\n",
    "        vector2 = text_to_vector(df_small_google_fix.name[j])\n",
    "\n",
    "        similar_combined = get_cosine(vector1, vector2)\n",
    "\n",
    "        # Append similarity scores and other attributes to lists\n",
    "        similar_score.append(similar_combined)\n",
    "        matched_amazon_combined.append(df_small_amazon_fix.combined_feature[i])\n",
    "        matched_google_combined.append(df_small_google_fix.combined_feature[j])\n",
    "        matched_amazon_title.append(df_small_amazon_fix.title[i])\n",
    "        matched_google_title.append(df_small_google_fix.name[j])\n",
    "        matched_google_id.append(df_small_google.idGoogleBase[j])\n",
    "        matched_amazon_id.append(df_small_amazon.idAmazon[i])\n",
    "\n",
    "        # Adding price attributes to matched titles dataframe\n",
    "        matched_amazon_price.append(df_small_amazon.price[i])\n",
    "        matched_google_price.append(df_small_google.price[j])\n",
    "\n",
    "    # Combine lists into a DataFrame\n",
    "    zippedList = list(zip(\n",
    "        matched_amazon_id,\n",
    "        matched_google_id,\n",
    "        similar_score,\n",
    "        matched_amazon_title,\n",
    "        matched_google_title,\n",
    "        matched_amazon_price,\n",
    "        matched_google_price\n",
    "    ))\n",
    "\n",
    "    all_match_score = pd.DataFrame(zippedList, columns=[\n",
    "        'matched_amazon_id',\n",
    "        'matched_google_id',\n",
    "        'similarity_score',\n",
    "        'matched_amazon_combined',\n",
    "        'matched_google_combined',\n",
    "        'matched_amazon_price',\n",
    "        'matched_google_price'\n",
    "    ])\n",
    "\n",
    "    sorted_data = all_match_score.sort_values('similarity_score')\n",
    "\n",
    "    # Find the max similarity for each item in the first list\n",
    "    top_match = sorted_data[-1:]\n",
    "\n",
    "    # Attach the matches with the max similarity to the main matched_list\n",
    "    matched_list = pd.concat([matched_list, top_match])\n",
    "\n",
    "# Sort the matched_list by similarity score in descending order\n",
    "sorted_match = matched_list.sort_values('similarity_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now thresholds is : 0.1\n",
      "length of predict match is : 145\n",
      "TP : 121\n",
      "FP : 24\n",
      "FN : 9\n",
      "TN : 18696\n",
      "\n",
      "Accuracy is : 0.9982493368700265\n",
      "precision is : 0.8344827586206897\n",
      "recall is : 0.9307692307692308\n",
      "============================================\n",
      "Now thresholds is : 0.2\n",
      "length of predict match is : 144\n",
      "TP : 121\n",
      "FP : 23\n",
      "FN : 9\n",
      "TN : 18567\n",
      "\n",
      "Accuracy is : 0.9982905982905983\n",
      "precision is : 0.8402777777777778\n",
      "recall is : 0.9307692307692308\n",
      "============================================\n",
      "Now thresholds is : 0.3\n",
      "length of predict match is : 141\n",
      "TP : 121\n",
      "FP : 20\n",
      "FN : 9\n",
      "TN : 18180\n",
      "\n",
      "Accuracy is : 0.998417894162575\n",
      "precision is : 0.8581560283687943\n",
      "recall is : 0.9307692307692308\n",
      "============================================\n",
      "Now thresholds is : 0.31\n",
      "length of predict match is : 141\n",
      "TP : 121\n",
      "FP : 20\n",
      "FN : 9\n",
      "TN : 18180\n",
      "\n",
      "Accuracy is : 0.998417894162575\n",
      "precision is : 0.8581560283687943\n",
      "recall is : 0.9307692307692308\n",
      "============================================\n",
      "Now thresholds is : 0.32\n",
      "length of predict match is : 140\n",
      "TP : 121\n",
      "FP : 19\n",
      "FN : 9\n",
      "TN : 18051\n",
      "\n",
      "Accuracy is : 0.9984615384615385\n",
      "precision is : 0.8642857142857143\n",
      "recall is : 0.9307692307692308\n",
      "============================================\n",
      "Now thresholds is : 0.33\n",
      "length of predict match is : 140\n",
      "TP : 121\n",
      "FP : 19\n",
      "FN : 9\n",
      "TN : 18051\n",
      "\n",
      "Accuracy is : 0.9984615384615385\n",
      "precision is : 0.8642857142857143\n",
      "recall is : 0.9307692307692308\n",
      "============================================\n",
      "Now thresholds is : 0.34\n",
      "length of predict match is : 136\n",
      "TP : 119\n",
      "FP : 17\n",
      "FN : 11\n",
      "TN : 17533\n",
      "\n",
      "Accuracy is : 0.9984162895927602\n",
      "precision is : 0.875\n",
      "recall is : 0.9153846153846154\n",
      "============================================\n",
      "Now thresholds is : 0.35\n",
      "length of predict match is : 135\n",
      "TP : 118\n",
      "FP : 17\n",
      "FN : 12\n",
      "TN : 17403\n",
      "\n",
      "Accuracy is : 0.9983475783475784\n",
      "precision is : 0.8740740740740741\n",
      "recall is : 0.9076923076923077\n",
      "============================================\n",
      "Now thresholds is : 0.36\n",
      "length of predict match is : 133\n",
      "TP : 118\n",
      "FP : 15\n",
      "FN : 12\n",
      "TN : 17145\n",
      "\n",
      "Accuracy is : 0.9984384037015616\n",
      "precision is : 0.8872180451127819\n",
      "recall is : 0.9076923076923077\n",
      "============================================\n",
      "Now thresholds is : 0.38\n",
      "length of predict match is : 129\n",
      "TP : 115\n",
      "FP : 14\n",
      "FN : 15\n",
      "TN : 16626\n",
      "\n",
      "Accuracy is : 0.9982707215265355\n",
      "precision is : 0.8914728682170543\n",
      "recall is : 0.8846153846153846\n",
      "============================================\n",
      "Now thresholds is : 0.4\n",
      "length of predict match is : 126\n",
      "TP : 115\n",
      "FP : 11\n",
      "FN : 15\n",
      "TN : 16239\n",
      "\n",
      "Accuracy is : 0.9984126984126984\n",
      "precision is : 0.9126984126984127\n",
      "recall is : 0.8846153846153846\n",
      "============================================\n",
      "Now thresholds is : 0.5\n",
      "length of predict match is : 114\n",
      "TP : 106\n",
      "FP : 8\n",
      "FN : 24\n",
      "TN : 14682\n",
      "\n",
      "Accuracy is : 0.9978407557354926\n",
      "precision is : 0.9298245614035088\n",
      "recall is : 0.8153846153846154\n",
      "============================================\n",
      "Now thresholds is : 0.6\n",
      "length of predict match is : 85\n",
      "TP : 82\n",
      "FP : 3\n",
      "FN : 48\n",
      "TN : 10917\n",
      "\n",
      "Accuracy is : 0.9953846153846154\n",
      "precision is : 0.9647058823529412\n",
      "recall is : 0.6307692307692307\n",
      "============================================\n",
      "Now thresholds is : 0.7\n",
      "length of predict match is : 62\n",
      "TP : 62\n",
      "FP : 0\n",
      "FN : 68\n",
      "TN : 7930\n",
      "\n",
      "Accuracy is : 0.9915632754342432\n",
      "precision is : 1.0\n",
      "recall is : 0.47692307692307695\n",
      "============================================\n",
      "Now thresholds is : 0.8\n",
      "length of predict match is : 35\n",
      "TP : 35\n",
      "FP : 0\n",
      "FN : 95\n",
      "TN : 4420\n",
      "\n",
      "Accuracy is : 0.9791208791208791\n",
      "precision is : 1.0\n",
      "recall is : 0.2692307692307692\n",
      "============================================\n",
      "Now thresholds is : 0.9\n",
      "length of predict match is : 13\n",
      "TP : 13\n",
      "FP : 0\n",
      "FN : 117\n",
      "TN : 1560\n",
      "\n",
      "Accuracy is : 0.9307692307692308\n",
      "precision is : 1.0\n",
      "recall is : 0.1\n",
      "============================================\n",
      "Now thresholds is : 1\n",
      "length of predict match is : 3\n",
      "TP : 3\n",
      "FP : 0\n",
      "FN : 127\n",
      "TN : 260\n",
      "\n",
      "Accuracy is : 0.6743589743589744\n",
      "precision is : 1.0\n",
      "recall is : 0.023076923076923078\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "# Load the truth small CSV\n",
    "true_match_df = pd.read_csv('amazon_google_truth_small.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Create a list of true matches\n",
    "true_match = (true_match_df['idAmazon'] + true_match_df['idGoogleBase']).tolist()\n",
    "\n",
    "# Thresholds list to find optimal performance\n",
    "thresholds = [0.1, 0.2, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.38, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "\n",
    "# Iterate through different thresholds\n",
    "for s in thresholds:\n",
    "    # Filter predicted matches based on the current threshold\n",
    "    predict_match_full = sorted_match.loc[sorted_match['similarity_score'] >= s]\n",
    "    predict_match = (predict_match_full['matched_amazon_id'] + predict_match_full['matched_google_id']).tolist()\n",
    "\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "\n",
    "    # Calculate True Positives (TP)\n",
    "    for i in range(0, len(predict_match)):\n",
    "        for j in range(0, len(true_match)):\n",
    "            if predict_match[i] == true_match[j]:\n",
    "                TP += 1\n",
    "\n",
    "    # Calculate False Negatives (FN) and False Positives (FP)\n",
    "    FN = len(true_match) - TP\n",
    "    FP = len(predict_match) - TP\n",
    "\n",
    "    # Calculate True Negatives (TN)\n",
    "    TN = len(predict_match) * len(true_match) - TP - FP - FN\n",
    "\n",
    "    # Calculate accuracy, precision, and recall\n",
    "    accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "\n",
    "    # Print evaluation metrics\n",
    "    print('Now thresholds is:', s)\n",
    "    print('Length of predict match is:', len(predict_match))\n",
    "    print('TP:', TP)\n",
    "    print('FP:', FP)\n",
    "    print('FN:', FN)\n",
    "    print('TN:', TN)\n",
    "    print('')\n",
    "    print('Accuracy is:', accuracy)\n",
    "    print('Precision is:', precision)\n",
    "    print('Recall is:', recall)\n",
    "    print('============================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This linkage method finds similarity based on the Amazon and Google titles and applies the cosine similarity function. Using the best-matched titles from both datasets and setting a threshold of 0.33 on the cosine similarity score is optimal, resulting in Accuracy: 0.896, Precision: 0.86, and Recall: 0.93.\n",
    "\n",
    "The cosine similarity function outperforms the editing-based and sequence-based string similarity functions.\n",
    "\n",
    "Overall, the performance based solely on titles is quite good. It could be further improved by applying cosine similarity to measure descriptions after removing insignificant words in the strings. Additionally, implementing price range elimination to reduce False Positives could be another layer of filtering that may enhance performance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ================================================================\n",
    " Blocking for effcient data linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efficient Data Linkage through Blocking\n",
    "\n",
    "# Impute Google manufacturers using other columns\n",
    "\n",
    "# Read data from CSV files\n",
    "df_google = pd.read_csv('google.csv', encoding='ISO-8859-1')\n",
    "df_amazon = pd.read_csv('amazon.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Replace missing values with empty strings\n",
    "df_amazon = df_amazon.replace(np.nan, '', regex=True)\n",
    "df_google = df_google.replace(np.nan, '', regex=True)\n",
    "\n",
    "# Extracting some features from 'name' and 'description' for matching\n",
    "amazon_name_extract = []\n",
    "amazon_des_extract = []\n",
    "\n",
    "for i in range(0, len(df_amazon)):\n",
    "    # Extract numeric values from the 'title' column\n",
    "    string = df_amazon['title'][i]\n",
    "    amazon_des_extract.append([int(s) for s in string.split() if s.isdigit()])\n",
    "\n",
    "# First blocking by price\n",
    "# Create 5 price blocks based on the spread of price data\n",
    "# 5 blocks: 0, >$0 - $25, $>25 - $45, $45 - $135, > $135\n",
    "\n",
    "df_amazon_block_1 = df_amazon[(df_amazon['price'] == 0) | (df_amazon['price'].isna())]\n",
    "df_amazon_block_2 = df_amazon[(df_amazon['price'] > 0) & (df_amazon['price'] <= 25)]\n",
    "df_amazon_block_3 = df_amazon[(df_amazon['price'] > 25) & (df_amazon['price'] <= 45)]\n",
    "df_amazon_block_4 = df_amazon[(df_amazon['price'] > 45) & (df_amazon['price'] <= 135)]\n",
    "df_amazon_block_5 = df_amazon[(df_amazon['price'] > 135)]\n",
    "\n",
    "# F_amazon_block_1 is empty, so 4 blocks left\n",
    "\n",
    "# Removing the unit and converting to a numeric value (price in GBP)\n",
    "df_google['price'] = df_google['price'].map(lambda x: x.rstrip(' gbp'))\n",
    "df_google['price'] = pd.to_numeric(df_google['price'])\n",
    "\n",
    "df_google_block_1 = df_google[(df_google['price'] == 0) | (df_google['price'].isna())]\n",
    "df_google_block_2 = df_google[(df_google['price'] > 0) & (df_google['price'] <= 25)]\n",
    "df_google_block_3 = df_google[(df_google['price'] > 25) & (df_google['price'] <= 45)]\n",
    "df_google_block_4 = df_google[(df_google['price'] > 45) & (df_google['price'] <= 135)]\n",
    "df_google_block_5 = df_google[(df_google['price'] > 135)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store matching pairs for each block\n",
    "block2_matching = []\n",
    "block3_matching = []\n",
    "block4_matching = []\n",
    "block5_matching = []\n",
    "\n",
    "# Reset the index of the dataframes for efficient iteration\n",
    "df_amazon_block_2 = df_amazon_block_2.reset_index(drop=True)\n",
    "df_google_block_2 = df_google_block_2.reset_index(drop=True)\n",
    "\n",
    "df_amazon_block_3 = df_amazon_block_3.reset_index(drop=True)\n",
    "df_google_block_3 = df_google_block_3.reset_index(drop=True)\n",
    "\n",
    "df_amazon_block_4 = df_amazon_block_4.reset_index(drop=True)\n",
    "df_google_block_4 = df_google_block_4.reset_index(drop=True)\n",
    "\n",
    "df_amazon_block_5 = df_amazon_block_5.reset_index(drop=True)\n",
    "df_google_block_5 = df_google_block_5.reset_index(drop=True)\n",
    "\n",
    "# Define a function for matching and appending to the appropriate block\n",
    "def match_and_append(amazon_df, google_df, matching_list):\n",
    "    for i in range(len(amazon_df)):\n",
    "        for j in range(len(google_df)):\n",
    "            amazon_id = amazon_df.loc[i, 'idAmazon']\n",
    "            google_id = google_df.loc[j, 'id']\n",
    "            matching_list.append((amazon_id, google_id))\n",
    "\n",
    "# Matching for each block\n",
    "match_and_append(df_amazon_block_2, df_google_block_2, block2_matching)\n",
    "match_and_append(df_amazon_block_3, df_google_block_3, block3_matching)\n",
    "match_and_append(df_amazon_block_4, df_google_block_4, block4_matching)\n",
    "match_and_append(df_amazon_block_5, df_google_block_5, block5_matching)\n",
    "\n",
    "# Combine all matching blocks into one list\n",
    "block_predict_match = block2_matching + block3_matching + block4_matching + block5_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b0000ycfcwhttp://www.google.com/base/feeds/snippets/9558419339728905800'"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_predict_list[2987]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[950, 0]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### e.g Extract number from features\n",
    "str = df_amazon['title'][0]\n",
    "[int(s) for s in str.split() if s.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2007]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### e.g. Extract string from name and decription \n",
    "str = \"learning quickbooks 2007\"\n",
    "[int(s) for s in str.split() if s.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ground truth data\n",
    "ground_truth_match_df = pd.read_csv('amazon_google_truth.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Combine two IDs into a string\n",
    "ground_truth_match = (ground_truth_match_df['idAmazon'] + ground_truth_match_df['idGoogleBase']).tolist()\n",
    "\n",
    "# Initialize the counting for results\n",
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0 \n",
    "fn = 0 \n",
    "\n",
    "for i in range(0, len(block_predict_match)):\n",
    "    for j in range(0,len(ground_truth_match)):\n",
    "        if block_predict_match[i] == ground_truth_match[j]:\n",
    "            tp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute Google manufacturers by other columns\n",
    "\n",
    "# Read data from CSV files\n",
    "df_google = pd.read_csv('google.csv', encoding='ISO-8859-1')\n",
    "df_amazon = pd.read_csv('amazon.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Replace missing values with empty strings\n",
    "df_amazon = df_amazon.replace(np.nan, '', regex=True)\n",
    "df_google = df_google.replace(np.nan, '', regex=True)\n",
    "\n",
    "# Extracting some features from 'name' and 'description' for matching\n",
    "amazon_name_extract = []\n",
    "amazon_des_extract = []\n",
    "\n",
    "for i in range(0, len(df_amazon)):\n",
    "    # Extract numeric values from the 'title' column\n",
    "    str = df_amazon['title'][i]\n",
    "    amazon_des_extract.append([int(s) for s in str.split() if s.isdigit()])\n",
    "\n",
    "# First blocking by price\n",
    "# Create 5 price blocks based on the spread of price data\n",
    "# 5 blocks: 0, >$0 - $25, $>25 -$45, $45 - $135, > $135\n",
    "\n",
    "df_amazon_block_1 = df_amazon[(df_amazon['price'] == 0) | (df_amazon['price'].isna())]\n",
    "df_amazon_block_2 = df_amazon[(df_amazon['price'] > 0) & (df_amazon['price'] <= 25)]\n",
    "df_amazon_block_3 = df_amazon[(df_amazon['price'] > 25) & (df_amazon['price'] <= 45)]\n",
    "df_amazon_block_4 = df_amazon[(df_amazon['price'] > 45) & (df_amazon['price'] <= 135)]\n",
    "df_amazon_block_5 = df_amazon[(df_amazon['price'] > 135)]\n",
    "\n",
    "# F_amazon_block_1 is empty, so 4 Blocks left\n",
    "\n",
    "# Removing the unit and converting to a numeric value (price in GBP)\n",
    "df_google['price'] = df_google['price'].map(lambda x: x.rstrip(' gbp'))\n",
    "df_google['price'] = pd.to_numeric(df_google['price'])\n",
    "\n",
    "df_google_block_1 = df_google[(df_google['price'] == 0) | (df_google['price'].isna())]\n",
    "df_google_block_2 = df_google[(df_google['price'] > 0) & (df_google['price'] <= 25)]\n",
    "df_google_block_3 = df_google[(df_google['price'] > 25) & (df_google['price'] <= 45)]\n",
    "df_google_block_4 = df_google[(df_google['price'] > 45) & (df_google['price'] <= 135)]\n",
    "df_google_block_5 = df_google[(df_google['price'] > 135)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efficient Data Linkage through Blocking\n",
    "\n",
    "# Impute Google manufacturers using other columns\n",
    "\n",
    "# Read data from CSV files\n",
    "df_google = pd.read_csv('google.csv', encoding='ISO-8859-1')\n",
    "df_amazon = pd.read_csv('amazon.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Replace missing values with empty strings\n",
    "df_amazon = df_amazon.replace(np.nan, '', regex=True)\n",
    "df_google = df_google.replace(np.nan, '', regex=True)\n",
    "\n",
    "# Extracting some features from 'name' and 'description' for matching\n",
    "amazon_name_extract = []\n",
    "amazon_des_extract = []\n",
    "\n",
    "for i in range(0, len(df_amazon)):\n",
    "    # Extract numeric values from the 'title' column\n",
    "    string = df_amazon['title'][i]\n",
    "    amazon_des_extract.append([int(s) for s in string.split() if s.isdigit()])\n",
    "\n",
    "# First blocking by price\n",
    "# Create 5 price blocks based on the spread of price data\n",
    "# 5 blocks: 0, >$0 - $25, $>25 - $45, $45 - $135, > $135\n",
    "\n",
    "df_amazon_block_1 = df_amazon[(df_amazon['price'] == 0) | (df_amazon['price'].isna())]\n",
    "df_amazon_block_2 = df_amazon[(df_amazon['price'] > 0) & (df_amazon['price'] <= 25)]\n",
    "df_amazon_block_3 = df_amazon[(df_amazon['price'] > 25) & (df_amazon['price'] <= 45)]\n",
    "df_amazon_block_4 = df_amazon[(df_amazon['price'] > 45) & (df_amazon['price'] <= 135)]\n",
    "df_amazon_block_5 = df_amazon[(df_amazon['price'] > 135)]\n",
    "\n",
    "# F_amazon_block_1 is empty, so 4 blocks left\n",
    "\n",
    "# Removing the unit and converting to a numeric value (price in GBP)\n",
    "df_google['price'] = df_google['price'].map(lambda x: x.rstrip(' gbp'))\n",
    "df_google['price'] = pd.to_numeric(df_google['price'])\n",
    "\n",
    "df_google_block_1 = df_google[(df_google['price'] == 0) | (df_google['price'].isna())]\n",
    "df_google_block_2 = df_google[(df_google['price'] > 0) & (df_google['price'] <= 25)]\n",
    "df_google_block_3 = df_google[(df_google['price'] > 25) & (df_google['price'] <= 45)]\n",
    "df_google_block_4 = df_google[(df_google['price'] > 45) & (df_google['price'] <= 135)]\n",
    "df_google_block_5 = df_google[(df_google['price'] > 135)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store matching pairs for each block\n",
    "block2_matching = []\n",
    "block3_matching = []\n",
    "block4_matching = []\n",
    "block5_matching = []\n",
    "\n",
    "# Reset the index of the dataframes for efficient iteration\n",
    "df_amazon_block_2 = df_amazon_block_2.reset_index(drop=True)\n",
    "df_google_block_2 = df_google_block_2.reset_index(drop=True)\n",
    "\n",
    "df_amazon_block_3 = df_amazon_block_3.reset_index(drop=True)\n",
    "df_google_block_3 = df_google_block_3.reset_index(drop=True)\n",
    "\n",
    "df_amazon_block_4 = df_amazon_block_4.reset_index(drop=True)\n",
    "df_google_block_4 = df_google_block_4.reset_index(drop=True)\n",
    "\n",
    "df_amazon_block_5 = df_amazon_block_5.reset_index(drop=True)\n",
    "df_google_block_5 = df_google_block_5.reset_index(drop=True)\n",
    "\n",
    "# Define a function for matching and appending to the appropriate block\n",
    "def match_and_append(amazon_df, google_df, matching_list):\n",
    "    for i in range(len(amazon_df)):\n",
    "        for j in range(len(google_df)):\n",
    "            amazon_id = amazon_df.loc[i, 'idAmazon']\n",
    "            google_id = google_df.loc[j, 'id']\n",
    "            matching_list.append((amazon_id, google_id))\n",
    "\n",
    "# Matching for each block\n",
    "match_and_append(df_amazon_block_2, df_google_block_2, block2_matching)\n",
    "match_and_append(df_amazon_block_3, df_google_block_3, block3_matching)\n",
    "match_and_append(df_amazon_block_4, df_google_block_4, block4_matching)\n",
    "match_and_append(df_amazon_block_5, df_google_block_5, block5_matching)\n",
    "\n",
    "# Combine all matching blocks into one list\n",
    "block_predict_match = block2_matching + block3_matching + block4_matching + block5_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of predict match is : 3\n",
      "TP : 982\n",
      "FR : 962696\n",
      "FN : 318\n",
      "TN : 1251817404\n",
      "\n",
      "Pair completeness PC is : 0.7553846153846154\n",
      "Reduction ratio RR is : 0.9992307692307693\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "# Load the ground truth data\n",
    "ground_truth_match_df = pd.read_csv('amazon_google_truth.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Combine two IDs into a string\n",
    "ground_truth_match = (ground_truth_match_df['idAmazon'] + ground_truth_match_df['idGoogleBase']).tolist()\n",
    "\n",
    "# Initialize the counting for results\n",
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0 \n",
    "fn = 0 \n",
    "\n",
    "for i in range(0, len(block_predict_match)):\n",
    "    for j in range(0,len(ground_truth_match)):\n",
    "        if block_predict_match[i] == ground_truth_match[j]:\n",
    "            tp += 1\n",
    "\n",
    "# Calculate false negatives (FN)\n",
    "fn = (len(ground_true_match)) - tp\n",
    "\n",
    "# Calculate false positives (FP)\n",
    "fp = len(block_predict_match) - tp\n",
    "\n",
    "# Calculate true negatives (TN)\n",
    "tn = len(block_predict_match) * len(ground_true_match) - tp - fp - fn\n",
    "\n",
    "# Calculate the total number of comparisons (N)\n",
    "n = len(block_predict_match) * len(ground_true_match)\n",
    "\n",
    "# Calculate Pair Completeness (PC)\n",
    "PC = tp / (tp + fn)\n",
    "\n",
    "# Calculate Reduction Ratio (RR)\n",
    "RR = 1 - ((tp + fp) / n)\n",
    "\n",
    "# Print the results\n",
    "print('Length of predict match is:', len(block_predict_match))\n",
    "print('TP:', tp)\n",
    "print('FP:', fp)\n",
    "print('FN:', fn)\n",
    "print('TN:', tn)\n",
    "print('')\n",
    "print('Pair completeness PC is:', PC)\n",
    "print('Reduction ratio RR is:', RR)\n",
    "\n",
    "print('============================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments:\n",
    "\n",
    "Choice of blocking method: The first blocking method involves dividing the data into 5 blocks based on the spread of price data: | 0 | >0 - 25 | >25 - 45 | 45 - 135 | > 135 |. This choice is informed by the quartiles and median of both Amazon and Google datasets.\n",
    "\n",
    "In the second stage, elements within each block are reorganized by extracting strings from the name and description fields.\n",
    "\n",
    "Methods related to the two quality measures:\n",
    "\n",
    "The blocking methods involve dividing the data by price into 4 blocks for each dataset. This reduction in data volume helps improve computational efficiency for data linkage.\n",
    "Pair Completeness (PC) is calculated as follows: PC = tp / (tp + fn). An increase in the proportion of actual positives matches correctly identified (TP) leads to an increase in Pair Completeness, indicating effective blocking.\n",
    "\n",
    "Reduction Ratio (RR) is calculated as: RR = 1 - (tp + fp) / n. A high RR indicates better performance of the blocking method, offering greater efficiency for record linkage between datasets.\n",
    "\n",
    "### =============================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
